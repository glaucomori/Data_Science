{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Fs295cf9VwVB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch # para acessar o framework PyTorch, o torch é similar tensorflow\n",
        "import torch.nn.functional as F # funções para as redes que serão usadas\n",
        "import torchvision # bibliotecas do pytorch para visão computacional\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time # trabalhar com valores de tempo (ex.: tempo de execução, tempo de resposta)\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pQ1-Tir8XnCW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.ToTensor () # definindo a conversão de imagem para tensor\n",
        "\n",
        "trainset = datasets.MNIST('./MNIST_data/', download=True, train=True, transform=transform) # carrega a parte de treino do dataset\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True) # cria um buffer para pegar os dados por partes\n",
        "\n",
        "valset = datasets.MNIST('./MNIST_data/', download=True, train=False, transform=transform) # carrega a parte de validação do dataset\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True) # cria um buffer para pegar os dados por partes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "8zsu1YDGbVLk",
        "outputId": "949c7e9c-c7d4-4b17-86e0-6a6ccda8812d"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'_SingleProcessDataLoaderIter' object has no attribute 'next'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m dataiter \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(trainloader) \u001b[39m# conferir se a estrutura de dados está representando a imagem corretamente (lendo corretamente a base de dados)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m imagens, etiquetas \u001b[39m=\u001b[39m dataiter\u001b[39m.\u001b[39;49mnext()\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mimshow(imagens[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39msqueeze(), cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgray_r\u001b[39m\u001b[39m'\u001b[39m); \u001b[39m# comando para visualizar\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: '_SingleProcessDataLoaderIter' object has no attribute 'next'"
          ]
        }
      ],
      "source": [
        "dataiter = iter(trainloader) # conferir se a estrutura de dados está representando a imagem corretamente (lendo corretamente a base de dados)\n",
        "imagens, etiquetas = dataiter.next()\n",
        "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r'); # comando para visualizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpK9IM6fcJko",
        "outputId": "bdfc9a1b-deb2-435f-862f-8a3876e584dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 28, 28])\n",
            "torch.Size([])\n"
          ]
        }
      ],
      "source": [
        "print(imagens[0].shape) # para verificar as dimensões do tensor de cada imagem\n",
        "print(etiquetas[0].shape) # para verificar as dimensões do tensor de cada etiqueta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsSh3RNWj-0Y"
      },
      "outputs": [],
      "source": [
        "# Inception >> Modelo de rede da Keras.io que também é usada pelo Facebook implementou para o reconhecimento facial.\n",
        "# A rede Inception é uma rede boa para quem está iniciando em deep learning.\n",
        "# Vamos copiar as camadas da rede Inception para esse módulo (https://keras.io/api/applications/inceptionv3/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXHrvqNhf4Y0"
      },
      "outputs": [],
      "source": [
        "class Modelo(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Modelo, self).__init__()\n",
        "        self.linear1 = nn.Linear(28*28, 128) # camada de entrada, 784 neurônios que se ligam a 128\n",
        "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neurônios que se ligam a 64\n",
        "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neurônios que se ligam a 10\n",
        "        # para a camada de saída não é necessário definir nada pois só precisamos pegar o output da camada interna 2\n",
        "\n",
        "    def forward(self,X):\n",
        "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada para a camada interna 1\n",
        "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para a camada interna 2\n",
        "        X = self.linear3(X) # função  de ativação da camada interna 2 para a camada de saída, nesse caso f(x) = x\n",
        "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omOtX413j7N9"
      },
      "outputs": [],
      "source": [
        "# TREINAR # a estrutura é definida pelo modelo escolhido (Inception)\n",
        "def treino(modelo, trainloader, device):\n",
        "\n",
        "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a política de atualização dos pesos e das bias\n",
        "    inicio = time() # timer para sabermos quanto tempo levou o treino\n",
        "\n",
        "    criterio = nn.NLLLoss() # definindo o critério para calcular a perda\n",
        "    EPOCHS = 10 # número de epochs que o algoritmo rodará ( um bom treinamento possui no mínimo 100 epochs)\n",
        "    modelo.train() # ativando o modo de treinamento do modelo\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        perda_acumulada = 0 # incialização da perda acumulada da epoch em questão\n",
        "\n",
        "        for imagens, etiquetas in trainloader:\n",
        "\n",
        "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens para 'vetores' de 28*28 casas para ficarem compatíveis\n",
        "            otimizador.zera_grad() # zerando os gradientes por conta  do ciclo anterior\n",
        "\n",
        "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
        "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
        "\n",
        "            perda_instantanea.backward() # back propagation a partir da perda\n",
        "\n",
        "            otimizador.step() # atualizando os pesos e as bias\n",
        "\n",
        "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
        "\n",
        "\n",
        "        else:\n",
        "            print('Epoch {} - Perda resultante: {}' .format(epoch+1, perda_acumulada/len(trainloader)))\n",
        "    print('\\nTempo de treino (em minutos) =' ,(time()-inicio)/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmkAPuQ2nx4k"
      },
      "outputs": [],
      "source": [
        "# VALIDAÇÃO # O algoritmo que vai verificar a base de dados com o que está acontecendo no treinamento, o que está sendo esperado\n",
        "# a estrutura é definida pelo modelo escolhido (Inception)\n",
        "\n",
        "def validacao(modelo, valloader, device):\n",
        "    conta_corretas, conta_todas = 0, 0\n",
        "    for imagens, etiquetas in valloader:\n",
        "        for i in range(len(etiquetas)):\n",
        "            img = imagens[i].view(1, 784)\n",
        "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
        "            with torch.no_grad():\n",
        "                logps = modelo(img.to(device)) # output do modelo em escala logaritmica\n",
        "\n",
        "\n",
        "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
        "            probab = list(ps.cpu().numpy()[0])\n",
        "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
        "            etiqueta_certa = etiquetas.numpy()[i]\n",
        "            if (etiqueta_certa == etiqueta_pred): # comparar a previsão com o valor correto\n",
        "                conta_corretas += 1\n",
        "            conta_todas += 1\n",
        "\n",
        "    print('Total de imagens testadas = ', conta_todas)\n",
        "    print('\\nPrecisão do modelo = {}%' .format(conta_corretas*100/conta_todas))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDid5T1vq7OM",
        "outputId": "1866e120-84e6-485e-9fc3-4954559cc9af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Modelo(\n",
              "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
              "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
              "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LEITURA DO MODELO # a estrutura é definida pelo modelo escolhido (Inception)\n",
        "modelo = Modelo() # incializa o modelo\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # modelo rodará na GPU se possível\n",
        "modelo.to(device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "58837b1b657ea91009af8409fc244ae3b5ccf93ea980d6fb6b80adc5f697f4cc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
